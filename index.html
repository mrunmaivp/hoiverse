<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="author" content="Mrunmai Phatak">
  <meta name="description" content="Research paper on ...">
  <title>HOIverse : A Synthetic Scene Graph Dataset With Human Object Interactions</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f9f9f9;
      color: #333;
      margin: 0;
      padding: 0;
    }
    header {
      background-color: #24292e;
      color: white;
      padding: 2rem 1rem;
      text-align: center;
    }
    main {
      max-width: 800px;
      margin: 2rem auto;
      padding: 2rem;
      background-color: #fff;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    h1, h2 {
      color: #222;
    }
    a {
      color: #0366d6;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    footer {
      text-align: center;
      padding: 1rem;
      background-color: #eee;
      margin-top: 2rem;
    }
  </style>
</head>
<body>
  <header>
    <h1>HOIverse : A Synthetic Scene Graph Dataset With Human Object Interactions</h1>
    <p>by Mrunmai Phatak, Julian Lorenz, Nico HÃ¶rmann, JÃ¶rg HÃ¤hner, Rainer Lienhart</p>
  </header>
  <main>
    <h2>Abstract</h2>
    <p>
     When humans and robotic agents coexist in an environment, scene understanding becomes crucial for the agents to carry out various downstream tasks like navigation and planning. Hence, an agent must be capable of localizing and identifying actions performed by the human. Current research lacks reliable datasets for performing scene understanding within indoor environments where humans are also a part of the scene. Scene Graphs enable us to generate a structured representation of a scene or an image to perform visual scene understanding. To tackle this, we present HOIverse a synthetic dataset at the intersection of scene graph and human-object interaction, consisting of accurate and dense relationship ground truths between humans and surrounding objects along with corresponding RGB images, segmentation masks, depth images and human keypoints. We compute parametric relations between various pairs of objects and human-object pairs, resulting in an accurate and unambiguous relation definitions. In addition, we benchmark our dataset on state-of-the-art scene graph generation models to predict parametric relations and human-object interactions. Through this dataset, we aim to accelerate research in the field of scene understanding
    </p>

    <h2>Links</h2>
    <ul>
      <li><a href="https://www.arxiv.org/abs/2506.19639" target="_blank">ðŸ“„ Read the paper on arXiv</a></li>
      <li><a href="https://github.com/mrunmaivp/hoiverse/" target="_blank">ðŸ’» View code on GitHub</a></li>
    </ul>
  </main>
  <footer>
    &copy; 2025 Your Name
  </footer>
</body>
</html>
